{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yUm5Z0NJaejk"
   },
   "source": [
    "## 1.1 Getting Data\n",
    "\n",
    "Let us consider a public database, called “Adult” dataset hosted on the UCI’s Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Adult), that contains approximately 32.000 observations about different financial parameters of US population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0\n",
      "workclass: 2799\n",
      "fnlwgt: 0\n",
      "education: 0\n",
      "educational-num: 0\n",
      "marital-status: 0\n",
      "occupation: 2809\n",
      "relationship: 0\n",
      "race: 0\n",
      "gender: 0\n",
      "capital-gain: 0\n",
      "capital-loss: 0\n",
      "hours-per-week: 0\n",
      "native-country: 857\n",
      "income: 0\n"
     ]
    }
   ],
   "source": [
    "# check total nan values in the dataset\n",
    "\n",
    "for column in data.columns:\n",
    "    print(column + \":\", sum(data[column] == \"?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_A_z3HyJaekc"
   },
   "source": [
    "### 1.4 Data Cleaning\n",
    "\n",
    "The most common steps are:\n",
    "\n",
    "+ **Sample the data**. If the amount of raw data is huge, processing all of them may require an extensive amount of processing power which may not be practical.  In this case, it is quite common to sample the input data to reduce the size of data that need to be processed.\n",
    "\n",
    "+ **Impute missing data**. It is quite common that some of the input records are incomplete in the sense that certain fields are missing or have input error.  In a typical tabular data format, we need to validate each record contains the same number of fields and each field contains the data type we expect. In case the record has some fields missing, we have the following choices: \n",
    "<small>\n",
    "* (a) Discard the whole record if it is incomplete; \n",
    "* (b) Infer the missing value based on the data from other records.  A common approach is to fill the missing data with the average, or the median.\n",
    "<small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sample the data into n equal parts. After sampling, replace \"?\" with NaN\n",
    "data = data.sample(frac=0.5)\n",
    "data = data.replace('?', np.nan)\n",
    "\n",
    "# Replace NaN with mean for numerical columns where \"?\" was replaced\n",
    "for column in data.columns:\n",
    "    if data[column].dtype != 'object':  # Check if column is numerical\n",
    "        data[column] = pd.to_numeric(data[column])  # Convert to numeric\n",
    "        mean_value = data[column].mean()\n",
    "        data[column] = data[column].fillna(mean_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: 0\n",
      "workclass: 0\n",
      "fnlwgt: 0\n",
      "education: 0\n",
      "educational-num: 0\n",
      "marital-status: 0\n",
      "occupation: 0\n",
      "relationship: 0\n",
      "race: 0\n",
      "gender: 0\n",
      "capital-gain: 0\n",
      "capital-loss: 0\n",
      "hours-per-week: 0\n",
      "native-country: 0\n",
      "income: 0\n"
     ]
    }
   ],
   "source": [
    "# count total \"?\" in each column and display each columns total nulls, use for loops and if else\n",
    "\n",
    "for column in data.columns:\n",
    "    print(column + \":\", sum(data[column] == \"?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dcYB5BE1aekd"
   },
   "source": [
    "+ **Normalize numeric value**. Normalize data is about transforming numeric data into a uniform range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age    fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
      "18140  0.410959  0.107441         0.733333           0.0           0.0   \n",
      "7420   0.369863  0.018766         0.533333           0.0           0.0   \n",
      "1845   0.041096  0.143388         0.600000           0.0           0.0   \n",
      "10960  0.246575  0.005428         0.600000           0.0           0.0   \n",
      "33068  0.000000  0.179165         0.400000           0.0           0.0   \n",
      "\n",
      "       hours-per-week  \n",
      "18140        0.346939  \n",
      "7420         0.397959  \n",
      "1845         0.346939  \n",
      "10960        0.397959  \n",
      "33068        0.295918  \n"
     ]
    }
   ],
   "source": [
    "numeric_columns = data.select_dtypes(include=['int', 'float']).columns\n",
    "data[numeric_columns] = data[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "# Min-Max scaling\n",
    "data_normalized = (data[numeric_columns] - data[numeric_columns].min()) / (data[numeric_columns].max() - data[numeric_columns].min())\n",
    "\n",
    "# Display the normalized data\n",
    "print(data_normalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IQf9B9Dcaekd"
   },
   "source": [
    "+ **Reduce dimensionality**. High dimensionality can be a problem for some machine learning methods.  There are two ways to reduce the number of input features.  One is about $removing$ $irrelevant$ input variables, another one is about $removing$ $redundant$ input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PC1       PC2\n",
      "0  0.131945 -0.082138\n",
      "1  0.057992  0.086781\n",
      "2 -0.255223 -0.045998\n",
      "3 -0.045885 -0.006842\n",
      "4 -0.346307  0.143557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)  # You can specify the number of components\n",
    "data_reduced = pca.fit_transform(data_normalized)\n",
    "\n",
    "# Create a DataFrame with reduced dimensions\n",
    "data_reduced_df = pd.DataFrame(data_reduced, columns=['PC1', 'PC2'])\n",
    "\n",
    "# Display the reduced data\n",
    "print(data_reduced_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Add derived features**. In some cases, we may need to compute additional attributes from existing attributes (f.e. converting a geo-location to a zip code, or converting the age to an age group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  workclass  fnlwgt     education  educational-num  \\\n",
      "18140   47  Local-gov  171095    Assoc-acdm               12   \n",
      "7420    44    Private   40024       HS-grad                9   \n",
      "1845    20  Local-gov  224229  Some-college               10   \n",
      "10960   35    Private   20308  Some-college               10   \n",
      "33068   17    Private  277112          11th                7   \n",
      "\n",
      "           marital-status       occupation   relationship   race  gender  \\\n",
      "18140  Married-civ-spouse     Adm-clerical           Wife  White  Female   \n",
      "7420   Married-civ-spouse     Craft-repair        Husband  White    Male   \n",
      "1845        Never-married  Exec-managerial  Not-in-family  White  Female   \n",
      "10960           Separated            Sales  Not-in-family  White    Male   \n",
      "33068       Never-married            Sales      Own-child  White    Male   \n",
      "\n",
      "       capital-gain  capital-loss  hours-per-week native-country income  \\\n",
      "18140             0             0              35  United-States   >50K   \n",
      "7420              0             0              40  United-States  <=50K   \n",
      "1845              0             0              35  United-States  <=50K   \n",
      "10960             0             0              40  United-States  <=50K   \n",
      "33068             0             0              30  United-States  <=50K   \n",
      "\n",
      "      age_group education_level_category marital_status_category  \n",
      "18140     40-49       Associate's Degree                 Married  \n",
      "7420      40-49                    Other                 Married  \n",
      "1845      18-29                    Other                  Single  \n",
      "10960     30-39                    Other               Separated  \n",
      "33068  Under 18                    Other                  Single  \n"
     ]
    }
   ],
   "source": [
    "# Derive Age Group\n",
    "def get_age_group(age):\n",
    "    if age < 18:\n",
    "        return 'Under 18'\n",
    "    elif age < 30:\n",
    "        return '18-29'\n",
    "    elif age < 40:\n",
    "        return '30-39'\n",
    "    elif age < 50:\n",
    "        return '40-49'\n",
    "    else:\n",
    "        return '50 and above'\n",
    "\n",
    "data['age_group'] = data['age'].apply(get_age_group)\n",
    "\n",
    "# Derive Education Level Category\n",
    "def get_education_level_category(education):\n",
    "    if 'Bachelor' in education:\n",
    "        return \"Bachelor's Degree or Higher\"\n",
    "    elif 'Masters' in education or 'Doctorate' in education:\n",
    "        return \"Master's Degree or Higher\"\n",
    "    elif 'Assoc' in education:\n",
    "        return \"Associate's Degree\"\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "data['education_level_category'] = data['education'].apply(get_education_level_category)\n",
    "\n",
    "\n",
    "marital_status_mapping = {\n",
    "    'Married-civ-spouse': 'Married',\n",
    "    'Married-AF-spouse': 'Married',\n",
    "    'Married-spouse-absent': 'Married',\n",
    "    'Separated': 'Separated',\n",
    "    'Divorced': 'Divorced',\n",
    "    'Widowed': 'Widowed',\n",
    "    'Never-married': 'Single'\n",
    "}\n",
    "data['marital_status_category'] = data['marital-status'].map(marital_status_mapping)\n",
    "\n",
    "# Display the DataFrame with derived features\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ **Discretize numeric value into categories**. Discretize data is about cutting a continuous value into ranges and assigning the numeric with the corresponding bucket of the range it falls on.  For numeric attribute, a common way to generalize it is to discretize it into ranges, which can be either constant width (variable height/frequency) or variable width (constant height)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age age_category\n",
      "18140   47        41-60\n",
      "7420    44        41-60\n",
      "1845    20         0-20\n",
      "10960   35        21-40\n",
      "33068   17         0-20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "num_bins = 5  # You can adjust the number of bins as needed\n",
    "bin_edges = [0, 20, 40, 60, 80, 100]\n",
    "\n",
    "bin_labels = ['0-20', '21-40', '41-60', '61-80', '81-100']\n",
    "\n",
    "data['age_category'] = pd.cut(data['age'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "print(data[['age', 'age_category']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ **Binarize categorical attributes**. Certain machine learning models only take binary input (or numeric input).  In this case, we need to convert categorical attribute into multiple binary attributes, while each binary attribute corresponds to a particular value of the category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age  fnlwgt  educational-num  capital-gain  capital-loss  \\\n",
      "18140   47  171095               12             0             0   \n",
      "7420    44   40024                9             0             0   \n",
      "1845    20  224229               10             0             0   \n",
      "10960   35   20308               10             0             0   \n",
      "33068   17  277112                7             0             0   \n",
      "\n",
      "       hours-per-week age_category  workclass_Federal-gov  \\\n",
      "18140              35        41-60                      0   \n",
      "7420               40        41-60                      0   \n",
      "1845               35         0-20                      0   \n",
      "10960              40        21-40                      0   \n",
      "33068              30         0-20                      0   \n",
      "\n",
      "       workclass_Local-gov  workclass_Never-worked  ...  age_group_Under 18  \\\n",
      "18140                    1                       0  ...                   0   \n",
      "7420                     0                       0  ...                   0   \n",
      "1845                     1                       0  ...                   0   \n",
      "10960                    0                       0  ...                   0   \n",
      "33068                    0                       0  ...                   1   \n",
      "\n",
      "       education_level_category_Associate's Degree  \\\n",
      "18140                                            1   \n",
      "7420                                             0   \n",
      "1845                                             0   \n",
      "10960                                            0   \n",
      "33068                                            0   \n",
      "\n",
      "       education_level_category_Bachelor's Degree or Higher  \\\n",
      "18140                                                  0      \n",
      "7420                                                   0      \n",
      "1845                                                   0      \n",
      "10960                                                  0      \n",
      "33068                                                  0      \n",
      "\n",
      "       education_level_category_Master's Degree or Higher  \\\n",
      "18140                                                  0    \n",
      "7420                                                   0    \n",
      "1845                                                   0    \n",
      "10960                                                  0    \n",
      "33068                                                  0    \n",
      "\n",
      "       education_level_category_Other  marital_status_category_Divorced  \\\n",
      "18140                               0                                 0   \n",
      "7420                                1                                 0   \n",
      "1845                                1                                 0   \n",
      "10960                               1                                 0   \n",
      "33068                               1                                 0   \n",
      "\n",
      "       marital_status_category_Married  marital_status_category_Separated  \\\n",
      "18140                                1                                  0   \n",
      "7420                                 1                                  0   \n",
      "1845                                 0                                  0   \n",
      "10960                                0                                  1   \n",
      "33068                                0                                  0   \n",
      "\n",
      "       marital_status_category_Single  marital_status_category_Widowed  \n",
      "18140                               0                                0  \n",
      "7420                                0                                0  \n",
      "1845                                1                                0  \n",
      "10960                               0                                0  \n",
      "33068                               1                                0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "# Display the DataFrame with one-hot encoded columns\n",
    "print(data_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fu798O5Gaeke"
   },
   "source": [
    "+ **Select, combine, aggregate data**. Designing the form of training data is the most important part of the whole predictive modeling exercise because the accuracy largely depends on whether the input features are structured in an appropriate form that provide strong signals to the learning algorithm. Rather than using the raw data as it is, it is quite common that multiple pieces of raw data need to be combined together, or aggregating multiple raw data records along some dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age     education      marital-status       occupation   relationship  \\\n",
      "18140   47    Assoc-acdm  Married-civ-spouse     Adm-clerical           Wife   \n",
      "7420    44       HS-grad  Married-civ-spouse     Craft-repair        Husband   \n",
      "1845    20  Some-college       Never-married  Exec-managerial  Not-in-family   \n",
      "10960   35  Some-college           Separated            Sales  Not-in-family   \n",
      "33068   17          11th       Never-married            Sales      Own-child   \n",
      "\n",
      "      income  \n",
      "18140   >50K  \n",
      "7420   <=50K  \n",
      "1845   <=50K  \n",
      "10960  <=50K  \n",
      "33068  <=50K  \n",
      "  education  avg_hours_per_week\n",
      "0      10th           36.791608\n",
      "1      11th           33.937155\n",
      "2      12th           35.114551\n",
      "3   1st-4th           38.442857\n",
      "4   5th-6th           39.423077\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "selected_features = ['age', 'education', 'marital-status', 'occupation', 'relationship', 'income']\n",
    "selected_data = data[selected_features]\n",
    "\n",
    "data['is_married'] = (data['marital-status'] == 'Married-civ-spouse') | (data['marital-status'] == 'Married-AF-spouse')\n",
    "\n",
    "aggregated_data = data.groupby('education')['hours-per-week'].mean().reset_index()\n",
    "aggregated_data.columns = ['education', 'avg_hours_per_week']\n",
    "\n",
    "# Display the processed data\n",
    "print(selected_data.head())\n",
    "print(aggregated_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [
    "y71OiIqaaelC",
    "5E6RdPMzaelZ",
    "2AZ0ad7Laelt",
    "zVkzcLWIaemY",
    "HBE-rQiDaemj",
    "y0sQ21GRaenD",
    "PtXcYFRBaenD",
    "rT7ZfM8TaenE",
    "K7jjUYSGaenN",
    "Eb-JMvMnaenP",
    "IMkfsZ17aenQ",
    "eM5NbwyhaenR",
    "51Pi3dLtaenq",
    "OHoC6jACaenv",
    "zHo67DaLaenw",
    "y9rLMwK_aenx",
    "QxjXzgEBaen5",
    "T_lM-XHRaen8",
    "2-acPef3aeoC"
   ],
   "name": "ch03_Descriptive_Statistics.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
